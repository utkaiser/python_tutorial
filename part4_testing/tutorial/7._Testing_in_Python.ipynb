{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Kurs zum Thema Testing in Python ist folgendermaßen gegliedert:\n",
    "1. Struktur\n",
    "2. Implementierung der Tests mit `pytest`\n",
    "3. Hilfreiche Funktionen\n",
    "4. Test Coverage\n",
    "5. Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tests werden normalerweise nicht in Jupyter Notebooks definiert und ausgeführt werden. Um in Jupyter Notebooks trotzdem das Modul `pytest` verwenden und demonstrieren zu können, nutzen wir daher im Folgenden das Modul `IPytest`. Für das Module `coverage` existiert eine solche Lösung in Jupyter Notebook nicht. Code Coverage Tests führen wir daher exemplarisch über eine `Shell` aus.\n",
    "* alle Funktionen und Tests dieses Tutorials befinden sich auch als Python-Dateien in diesem git. <br> Öffne hierzu `PyCharm` --> `Check out from Version Control` --> `git` und gib den `URL`-Link ein.\n",
    "* Öffne anschließend `Settings` --> `Tools` --> `Python Integrated Tools` und wähle als `Default test runner` `pytest`. Klicke `OK` um die Einstellung zu speichern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Struktur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachment:grafik.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hauptskript, das alle wichtigen Funktionsaufrufe enthält (`mainFunction.py`)\n",
    "* Skript mit allen nötigen Funktionsdefinitionen (`functions.py`)\n",
    "* Skript mit allen benötigten Tests für functions.R (`tests.py`)\n",
    "* Optionaler Ordner mit kleinen Testdatensätzen (Testdaten)<br>\n",
    "<br>\n",
    "* Ein Testskript für jedes Skript mit Funktionsdefinitionen (Konzept Unittesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alle relevanten Pakete müssen geladen werden\n",
    "* Skript mit allen Funktionen muss geladen werden\n",
    "* Body enthält alle Tests für das Testskript `Functions.py`\n",
    "* Alphabetisch geordnet\n",
    "* Optional: gruppiert nach Codeblöcken (Preprocessing, Forecast, …)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informationen zur Installation von `pytest` findest Du hier: https://docs.pytest.org/en/latest/getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pytests` ermöglichen einfaches und schnelles Testing\n",
    "* wenig Codezeilen benötigt\n",
    "* Alternative: Framework `unittest`<br>\n",
    "<br>\n",
    "* schreibe zusammengehörige Tests in eine Funktion mit `test_>>function name<<_>>short description<<():`\n",
    "* die kurze Beschreibung liefert eine Erklärung, was getestet wird (z.B. `happypath`, `extremepath`)\n",
    "* schreibe als Kommentar dahinter, was der Test macht. Dies hilft beim Debugging von fehlerhaften Tests. Hilfreich sind dort auch Hinweise, ob es sich z.B. um einen Normaltest oder einen Extremtest handelt.\n",
    "* Funktion für einen Test ist `assert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_2(x):\n",
    "    return x*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Führe Tests in dem Notebook aus<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "#1. Möglichkeit\n",
    "def test_multiply_by_2_happypath(): #test for correct execution (different values)\n",
    "    assert multiply_by_2(0) == 0\n",
    "    assert multiply_by_2(1) == 2\n",
    "    assert multiply_by_2(2) == 4\n",
    "    assert multiply_by_2(3) == 6\n",
    "    \n",
    "#2. Möglichkeit\n",
    "@pytest.mark.parametrize('input,expected', [ #schreibe in Anführungszeichen die Variablennamen\n",
    "    (-1, -2),\n",
    "    (-3, -6),\n",
    "    (4, 8),\n",
    "    (5, 10)\n",
    "])\n",
    "def test_multiply_by_2_parametrized_happypath(input, expected): #test for correct execution (different values)\n",
    "    assert multiply_by_2(input) == expected,\"test failed because \"+str(input)+\"*2/=\"+str(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....                                                                    [100%]\n"
     ]
    }
   ],
   "source": [
    "ipytest.run('-qq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Führe Tests in einem anderen Notebook aus<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Öffne hierzu `PyCharm` wie oben beschrieben und führe die `Shel1 1` aus.\n",
    "* `Shell 1` ist ein `PowerShell`-Skript, Hinweise zur Ausführung unter: https://www.heise.de/tipps-tricks/Windows-Powershell-Skript-ausfuehren-4672163.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hilfreiche Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dateipfad ausgeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die Funktion `.getcwd()` aus dem Paket `os` gibt den Pfad des Projekts zurück.\n",
    "* benutzte keine hart codierten Pfade, auch nicht in Tests\n",
    "* Es hat sich herausgestellt, dass dadurch wesentlich leichter von verschiedenen Benutzern Tests erstellt und geprüft werden können.\n",
    "* Die Pfade in den Tests einfach ausgehend vom Projektpfad mit `os.getcwd()` angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/udis/Documents/Werkstudentenjob/Python_Tutorial/Testing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ermöglicht, gewisse Fehlermeldungen bei Tests abzufangen\n",
    "* Falls innerhalb einer Funktion 2-mal Fehler mit selber Klasse geprüft werden, muss zusätzlich auf die Fehlermeldung wie bei der 2. Möglichkeit geprüft werden, um genau bestimmen zu können, wo der Abbruch stattfindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean] -qq \n",
    "\n",
    "def test_multiply_by_2_extremepath(): #test for correct execution (expecting error)\n",
    "    with pytest.raises(ZeroDivisionError):#erwartet, dass ein ZeroDivisionError geworfen wird; passiert das nicht wird\n",
    "        1 / multiply_by_2(0)                             #ein Fehler geworfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Fixture`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Das Ziel von `Fixtures` ist, eine fixe Startlinie zu definieren, wodurch Tests zuverlässig ausgeführt werden können.\n",
    "* `pytest` `Fixtures` stellen Daten zur Verfügung und bilden das Setup für deine Tests.\n",
    "* Ausführlichere Angaben zu `Fixture` findest Du hier: https://docs.pytest.org/en/2.9.1/fixture.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@pytest.fixture\n",
    "def fixture_example():\n",
    "    datapath = os.getcwd() +\"/Aufgaben/test/Unit/data/Abverkauf.csv\"\n",
    "    return pd.read_csv(datapath, delimiter = \";\", encoding='latin-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean] -qq \n",
    "\n",
    "def test_multiply_by_2_happypath_2(fixture_example): #test for correct execution\n",
    "    assert fixture_example[\"Material\"][0] == 9148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nutzbar in Entwicklungsumgebungen wie z.B. `PyCharm`, `Eclipse`, ...\n",
    "* Schlagen Tests fehl, verwendet man den Debugger mit entsprechend gesetzten Break Points, um die Ausführung Schritt für Schritt durchzugehen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachment:image.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Der rote Punkt ist ein Break Point. Betätigt man die grüne Fliege/Bug im rechten oberen Bildrand, startet der Debugger und der Interpreter stoppt, sobald der Break Point erreicht wird.\n",
    "* Nun lassen sich die Werte der Parameter ansehen (links unten im Bild) und die Ausführung zeilenweise durchgehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Installiere folgende Module\n",
    "    * Coverage: *pip install coverage*, *pip install pytest-cov*\n",
    "    * `HTML`-Darstellung mit *pip install pytest-html*\n",
    "* Führe nun `Shell 2` aus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Einfache Version:</b><br>\n",
    "<blockquote>\n",
    "    coverage run -m pytest arg1 arg2 arg3$\\;\\;\\;$ führt Tests aus<br>\n",
    "    coverage report -i $\\;\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;\\;$  $\\;\\;\\;\\;\\;\\;$ liefert Ergebnisse im Fenster<br>\n",
    "    coverage html $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$ liefert ausführliche Ergebnisse im HTML-Format</blockquote><br>\n",
    "<b>Speichern der Ergebnisse in XML-Dateien:</b><br>\n",
    "<blockquote>python3 -m pytest -v --cov-report xml:target_dir/py_cov.xml --cov=algorithm_implementation --junitxml=target_dir/py-test-results.xml ./tests<br></blockquote>\n",
    "<b>Speichern der Ergebnisse in HTML-Dateien:</b><br>\n",
    "<blockquote>python3 -m pytest -v --cov-report html:target_dir/py_cov.html --cov=algorithm_implementation --html=target_dir/py-test-results.html ./tests.py<br></blockquote>\n",
    "<b>Nur Coverage:</b><br>\n",
    "<blockquote>python3 -m pytest -v --cov-report xml:file</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test Coverage misst den Prozentsatz der Zeilen des Skripts `functions.py`, die durch die Tests abgedeckt sind.\n",
    "* Test Coverage ist ein notwendiges Kriterium für qualitativ hochwertigen Code, jedoch kein hinreichendes Kriterium\n",
    "* Ziel ist ein möglichst hoher Test Coverage durch <b>sinnvolle</b> Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_value(x):\n",
    "    if x>=0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..                                                                       [100%]\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean] -qq \n",
    "\n",
    "def test_absolute_value_happypath_positive(): #test for correct excecution (positive values)\n",
    "    assert absolute_value(0) == 0\n",
    "    assert absolute_value(1) == 1\n",
    "    assert absolute_value(2) == 2\n",
    "    assert absolute_value(3) == 3\n",
    "    \n",
    "def test_absolute_value_happypath_negative(): #test correct excecution (negative values)\n",
    "    assert absolute_value(0) == 0\n",
    "    assert absolute_value(-1) == 1\n",
    "    assert absolute_value(2) == 2\n",
    "    assert absolute_value(-3) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* die Funktion besitzt 4 Zeilen Code \n",
    "* beim ersten Test würde man eine Test Coverage von 50% erhalten, da keine negativen Werte getest werden\n",
    "* beim zweiten Test erhält man eine Test Coverage von 100%, da sowohl positive als auch negative Werte getestet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehr Informationen zu `pytest` findest Du hier:\n",
    "* https://docs.pytest.org/en/latest/talks.html\n",
    "* https://docs.pytest.org/en/2.8.7/fixture.html\n",
    "* https://docs.pytest.org/en/latest/xunit_setup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Aufgaben befinden sich in der `PDF`-Datei *aufgaben_testing_in_python* im Ordner *Aufgaben*, die dazugehörigen Daten im Ordner *data*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}